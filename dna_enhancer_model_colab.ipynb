{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/dipandhali2021/Enhancer_BiLSTMAtt-ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose from 'atomic' | 'EIIP' | 'BFDNA' | 'numeric'\n",
    "DNA_encoding_scheme='BFDNA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with  open(\"/content/Enhancer_BiLSTMAtt-ResNet/data/human_mouse/enhancer.train.txt\") as f:\n",
    "       enhancer_train = f.readlines()\n",
    "       enhancer_train = [s.strip() for s in enhancer_train]\n",
    "with  open(\"/content/Enhancer_BiLSTMAtt-ResNet/data/human_mouse/enhancer.test.txt\") as f:\n",
    "       enhancer_test = f.readlines()\n",
    "       enhancer_test = [s.strip() for s in enhancer_test]\n",
    "with  open(\"/content/Enhancer_BiLSTMAtt-ResNet/data/human_mouse/non.enhancer.train.txt\") as f:\n",
    "       non_enhancer_train = f.readlines()\n",
    "       non_enhancer_train = [s.strip() for s in non_enhancer_train]\n",
    "with  open(\"/content/Enhancer_BiLSTMAtt-ResNet/data/human_mouse/non.enhancer.test.txt\") as f:\n",
    "       non_enhancer_test = f.readlines()\n",
    "       non_enhancer_test = [s.strip() for s in non_enhancer_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_header(data):\n",
    "    data_new = []\n",
    "    for i in range(1,len(data),2):\n",
    "        data_new.append(data[i])\n",
    "    \n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_fixed_length(sequences, length=200):\n",
    "    fixed_length_sequences = []\n",
    "    for seq in sequences:\n",
    "        # Strip to length of 200\n",
    "        if len(seq) > length:\n",
    "            fixed_length_sequences.append(seq[:length])\n",
    "        else:\n",
    "            # If shorter, pad with 'N' (or other character of your choice)\n",
    "            fixed_length_sequences.append(seq.ljust(length, 'N'))  # Use 'N' for padding\n",
    "    return fixed_length_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhancer_train = remove_header(enhancer_train)\n",
    "non_enhancer_train = remove_header(non_enhancer_train)\n",
    "enhancer_test = remove_header(enhancer_test)\n",
    "non_enhancer_test = remove_header(non_enhancer_test)\n",
    "\n",
    "\n",
    "\n",
    "enhancer_train = ensure_fixed_length(enhancer_train, length=200)\n",
    "non_enhancer_train = ensure_fixed_length(non_enhancer_train, length=200)\n",
    "enhancer_test = ensure_fixed_length(enhancer_test, length=200)\n",
    "non_enhancer_test = ensure_fixed_length(non_enhancer_test, length=200)\n",
    "\n",
    "\n",
    "print(len(enhancer_train),len(enhancer_train[0]))\n",
    "print(len(enhancer_test),len(enhancer_test[0]))\n",
    "print(len(non_enhancer_train),len(non_enhancer_train[0]))\n",
    "print(len(non_enhancer_test),len(non_enhancer_test[0]))\n",
    "train_x = np.concatenate([enhancer_train, non_enhancer_train], axis=0)\n",
    "test_x = np.concatenate([enhancer_test, non_enhancer_test], axis=0)\n",
    "print(len(train_x),len(test_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.concatenate([np.ones((len(enhancer_train),)), np.zeros((len(non_enhancer_train),))], axis=0)  \n",
    "test_y = np.concatenate([np.ones((len(enhancer_test),)), np.zeros((len(non_enhancer_test),))], axis=0)\n",
    "print(train_y.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_matrix(seq_matrix, encoding_scheme):\n",
    "    \"\"\"Encodes DNA sequences using the specified encoding scheme.\"\"\"\n",
    "    if encoding_scheme == 'BFDNA':\n",
    "        # BFDNA Encoding\n",
    "        def compute_bfdna(sequence):\n",
    "            total_length = len(sequence)\n",
    "            base_counts = {base: sequence.count(base) for base in 'ACGTN'}\n",
    "            return [base_counts[base] / total_length for base in sequence]\n",
    "\n",
    "        def scale_and_round(sequence_bfdna, scale_factor=100):\n",
    "            return [round(value * scale_factor) for value in sequence_bfdna]\n",
    "        \n",
    "        return [scale_and_round(compute_bfdna(sequence)) for sequence in seq_matrix]\n",
    "\n",
    "    elif encoding_scheme == 'numeric':\n",
    "        # Numeric Mapping\n",
    "        ind_to_char = ['A', 'T', 'C', 'G', 'N']\n",
    "        char_to_ind = {char: i for i, char in enumerate(ind_to_char)}\n",
    "        return [[char_to_ind[i] for i in s] for s in seq_matrix]\n",
    "\n",
    "    elif encoding_scheme == 'atomic':\n",
    "        # Atomic Mapping\n",
    "        char_to_atomic_number = {'A': 70, 'T': 58, 'C': 78, 'G': 66, 'N': 0}\n",
    "        return [[char_to_atomic_number[i] for i in s] for s in seq_matrix]\n",
    "\n",
    "    elif encoding_scheme == 'EIIP':\n",
    "        # EIIP Mapping\n",
    "        char_to_eiip = {'A': 0.1260, 'C': 0.1340, 'G': 0.0806, 'T': 0.1335, 'N': 0.0}\n",
    "        \n",
    "        def scale_eiip(sequence_eiip, scale_factor=100):\n",
    "            return [round(value * scale_factor, 2) for value in sequence_eiip]\n",
    "        \n",
    "        return [scale_eiip([char_to_eiip[i] for i in s]) for s in seq_matrix]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown encoding scheme: {encoding_scheme}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = encode_matrix(train_x,encoding_scheme=DNA_encoding_scheme)\n",
    "test_x = encode_matrix(test_x,encoding_scheme=DNA_encoding_scheme)\n",
    "train_x = np.array(train_x)\n",
    "test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sn_sp_acc_mcc(true_label, predict_label, pos_label=1):\n",
    "    import numpy as np\n",
    "    import math\n",
    "\n",
    "    pos_num = np.sum(true_label == pos_label)\n",
    "    neg_num = true_label.shape[0] - pos_num\n",
    "\n",
    "    tp = np.sum((true_label == pos_label) & (predict_label == pos_label))\n",
    "    tn = np.sum((true_label != pos_label) & (predict_label != pos_label))\n",
    "    fn = pos_num - tp\n",
    "    fp = neg_num - tn\n",
    "\n",
    "    # Sensitivity (Recall) and Specificity\n",
    "    sn = tp / pos_num if pos_num > 0 else 0\n",
    "    sp = tn / neg_num if neg_num > 0 else 0\n",
    "\n",
    "    # Accuracy\n",
    "    acc = (tp + tn) / (pos_num + neg_num) if (pos_num + neg_num) > 0 else 0\n",
    "\n",
    "    # Precision\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "    # CSI\n",
    "    csi = precision + sn - 1\n",
    "\n",
    "    # G-mean\n",
    "    gmean = math.sqrt(sn * sp)\n",
    "\n",
    "    # MCC\n",
    "    tp = np.array(tp, dtype=np.float64)\n",
    "    tn = np.array(tn, dtype=np.float64)\n",
    "    fp = np.array(fp, dtype=np.float64)\n",
    "    fn = np.array(fn, dtype=np.float64)\n",
    "\n",
    "    mcc_denominator = ((tp + fp) * (fp + tn) + (tp + fn) * (fn + tn))\n",
    "    mcc = (2 * (tp * tn - fp * fn)) /  np.sqrt(mcc_denominator) if mcc_denominator > 0 else 0\n",
    "\n",
    "    # Kappa\n",
    "    kappa = (2 * (tp * tn - fp * fn)) / mcc_denominator if mcc_denominator > 0 else 0\n",
    "\n",
    "    return sn, sp, acc, mcc, kappa, csi, gmean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    maxlen = 200\n",
    "    max_features = 100 \n",
    "    embedding_dims = 128\n",
    "    input = Input(shape=(maxlen,))\n",
    "    embedding = Embedding(max_features, embedding_dims, input_length=maxlen)(input)\n",
    "\n",
    "    # Convolutional branch\n",
    "    conv = Conv1D(64, kernel_size=5, activation='relu')(embedding)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = GlobalMaxPool1D()(conv)\n",
    "\n",
    "    # LSTM branch\n",
    "    lstm = Bidirectional(LSTM(64, return_sequences=True))(embedding)\n",
    "    lstm = GlobalMaxPool1D()(lstm)\n",
    "\n",
    "    # Combine branches\n",
    "    combined = Concatenate()([conv, lstm])\n",
    "    combined = Dense(64, activation='relu')(combined)\n",
    "    combined = Dropout(0.5)(combined)\n",
    "    output = Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=1e-4),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training of model\n",
    "\n",
    "model_layer1 = define_model()\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "# Train layer 1 model\n",
    "history1 = model_layer1.fit(\n",
    "    train_x, \n",
    "    train_y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,  # Using 20% of training data for validation\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model_layer1.save_weights(f\"/content/Enhancer_BiLSTMAtt-ResNet/Enhancer-LSTMAtt/ResNet+LSTM+Attention({DNA_encoding_scheme}).weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not training uncomment next line\n",
    "# model_layer1 = define_model()\n",
    "model_layer1.load_weights(f\"/content/Enhancer_BiLSTMAtt-ResNet/Enhancer-LSTMAtt/ResNet+LSTM+Attention({DNA_encoding_scheme}).weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Your existing model prediction logic\n",
    "res1 = model_layer1.predict(test_x)  # Prediction\n",
    "pred1 = np.squeeze(res1, axis=-1)\n",
    "f1 = pred1 > 0.5\n",
    "pred1[f1] = 1\n",
    "pred1[pred1 < 0.6] = 0\n",
    "\n",
    "# Call to your sn_sp_acc_mcc function (not shown in the code snippet you provided)\n",
    "sn, sp, acc, mcc, kappa, csi, gmean = sn_sp_acc_mcc(test_y, pred1, pos_label=1)\n",
    "\n",
    "print(f\"Sensitivity (SN): {sn:.4f}\")\n",
    "print(f\"Specificity (SP): {sp:.4f}\")\n",
    "print(f\"Accuracy (ACC): {acc:.4f}\")\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
    "print(f\"Critical Success Index (CSI): {csi:.4f}\")\n",
    "print(f\"Geometric Mean (G-mean): {gmean:.4f}\")\n",
    "\n",
    "# ROC curve calculations and AUC\n",
    "FPR_1, TPR_1, threshold_1 = roc_curve(test_y, model_layer1.predict(test_x), pos_label=1)\n",
    "AUC_1 = auc(FPR_1, TPR_1)\n",
    "print(AUC_1)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title('ROC curves')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.plot(FPR_1, TPR_1, color='r', label='Enhancer (AUC={:.4f})'.format(AUC_1))\n",
    "plt.plot([0, 1], [0, 1], color='m', linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# --- Confusion Matrix Plotting ---\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(test_y, pred1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', cbar=False,\n",
    "            xticklabels=['No enhancer', 'Enhancer'], yticklabels=['No enhancer', 'Enhancer'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Confusion Matrix for Numeric')\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Actual Values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coding for K fold Validation\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPool1D, Bidirectional, LSTM, Dense, Dropout, Concatenate, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def define_model():\n",
    "    maxlen = X.shape[1]  \n",
    "    max_features = 100  \n",
    "    embedding_dims = 128\n",
    "    input = Input(shape=(maxlen,))\n",
    "    embedding = Embedding(max_features, embedding_dims, input_length=maxlen)(input)\n",
    "\n",
    "    # Convolutional branch\n",
    "    conv = Conv1D(64, kernel_size=5, activation='relu')(embedding)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = GlobalMaxPool1D()(conv)\n",
    "\n",
    "    # LSTM branch\n",
    "    lstm = Bidirectional(LSTM(64, return_sequences=True))(embedding)\n",
    "    lstm = GlobalMaxPool1D()(lstm)\n",
    "\n",
    "    # Combine branches\n",
    "    combined = Concatenate()([conv, lstm])\n",
    "    combined = Dense(64, activation='relu')(combined)\n",
    "    combined = Dropout(0.5)(combined)\n",
    "    output = Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=1e-4),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def plot_kfold_roc_curves(X, y, k=5, epochs=50, batch_size=32):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    results = {\n",
    "        'SN': [],\n",
    "        'SP': [],\n",
    "        'ACC': [],\n",
    "        'MCC': [],\n",
    "        'AUC': []\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = define_model()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                  validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "        y_pred = model.predict(X_val).ravel()\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_val, y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        sens, spec, acc, mcc = calculate_metrics(y_val, y_pred)\n",
    "\n",
    "        results['SN'].append(sens)\n",
    "        results['SP'].append(spec)\n",
    "        results['ACC'].append(acc)\n",
    "        results['MCC'].append(mcc)\n",
    "        results['AUC'].append(roc_auc)\n",
    "\n",
    "        plt.plot(fpr, tpr, label=f'Fold {fold + 1} (AUC={roc_auc:.4f})', alpha=0.8)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.index = [f'Fold {i+1}' for i in range(k)]\n",
    "    df.loc['Mean'] = df.mean()\n",
    "    df = df.round(4)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nPerformances of 5-fold cross-validation:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df.to_string())\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Use the function\n",
    "results_df = plot_kfold_roc_curves(train_x, train_y, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
